{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/dm/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-04 21:03:23.536895: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-04 21:03:23.674149: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-04 21:03:24.158873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:/home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:\n",
      "2022-11-04 21:03:24.158943: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:/home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:\n",
      "2022-11-04 21:03:24.158949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import get_scheduler, DefaultDataCollator\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "PRETRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    29600\n",
      "1     6415\n",
      "Name: s_label, dtype: int64\n",
      "# of distinct data:\t 7987\n",
      "# of data:\t 36015\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>q'</th>\n",
       "      <th>r'</th>\n",
       "      <th>s_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8089</th>\n",
       "      <td>2248</td>\n",
       "      <td>Seriously ? That 's your reasoning ?</td>\n",
       "      <td>Er , no . That is AnswersinGenesis ' reasoning...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>Seriously ? That 's your reasoning ?</td>\n",
       "      <td>Are you having difficulties</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29515</th>\n",
       "      <td>8210</td>\n",
       "      <td>Let me get this straight . We ca n't force a w...</td>\n",
       "      <td>Yes because it is `` officially `` a life . Wh...</td>\n",
       "      <td>AGREE</td>\n",
       "      <td>We ca n't force a woman to give birth if she d...</td>\n",
       "      <td>Yes because it is `` officially `` a life .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16819</th>\n",
       "      <td>4768</td>\n",
       "      <td>Foolish Clergymen . How can this work ? How ca...</td>\n",
       "      <td>You know , that sounds exactly what you are do...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>Nothing in the bible is to be beleived unless ...</td>\n",
       "      <td>You know , that sounds exactly what you are do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                                  q  \\\n",
       "8089   2248               Seriously ? That 's your reasoning ?   \n",
       "29515  8210  Let me get this straight . We ca n't force a w...   \n",
       "16819  4768  Foolish Clergymen . How can this work ? How ca...   \n",
       "\n",
       "                                                       r         s  \\\n",
       "8089   Er , no . That is AnswersinGenesis ' reasoning...  DISAGREE   \n",
       "29515  Yes because it is `` officially `` a life . Wh...     AGREE   \n",
       "16819  You know , that sounds exactly what you are do...  DISAGREE   \n",
       "\n",
       "                                                      q'  \\\n",
       "8089                Seriously ? That 's your reasoning ?   \n",
       "29515  We ca n't force a woman to give birth if she d...   \n",
       "16819  Nothing in the bible is to be beleived unless ...   \n",
       "\n",
       "                                                      r'  s_label  \n",
       "8089                         Are you having difficulties        0  \n",
       "29515        Yes because it is `` officially `` a life .        1  \n",
       "16819  You know , that sounds exactly what you are do...        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/Batch_answers - train_data (no-blank).csv' )\n",
    "\n",
    "# drop unnecessary columns\n",
    "df_train = df_train.drop(['Unnamed: 6', 'total no.: 7987'], axis=1)\n",
    "\n",
    "# remove quotes\n",
    "df_train['q'] = df_train['q'].str.strip('\"')\n",
    "df_train['r'] = df_train['r'].str.strip('\"')\n",
    "df_train[\"q'\"] = df_train[\"q'\"].str.strip('\"')\n",
    "df_train[\"r'\"] = df_train[\"r'\"].str.strip('\"')\n",
    "\n",
    "# drop duplicated rows\n",
    "df_train = df_train.drop_duplicates()\n",
    "\n",
    "# numerical s\n",
    "df_train['s_label'] = (df_train['s'] == 'AGREE').astype(int)\n",
    "\n",
    "# some information about the dataset\n",
    "print(df_train['s_label'].value_counts())\n",
    "print('# of distinct data:\\t', len(df_train['id'].unique()))\n",
    "print('# of data:\\t', len(df_train))\n",
    "\n",
    "# save cleaned dataset\n",
    "df_train.to_csv('data/train.tsv', sep='\\t', index=False)\n",
    "\n",
    "# load cleaned dataset\n",
    "df_train = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of unmatch data 5865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32666</th>\n",
       "      <td>32666</td>\n",
       "      <td>What is the main point?</td>\n",
       "      <td>C.S . Lewis also pointed out that even our abi...</td>\n",
       "      <td>{'answer_start': [34], 'text': ['even our abil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23354</th>\n",
       "      <td>23354</td>\n",
       "      <td>What is the main point?</td>\n",
       "      <td>Wait a minute , I fail to see how it not being...</td>\n",
       "      <td>{'answer_start': [0], 'text': ['Wait a minute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28625</th>\n",
       "      <td>28625</td>\n",
       "      <td>What is the main point?</td>\n",
       "      <td>Why do suppose exaggeration and embellishment ...</td>\n",
       "      <td>{'answer_start': [61], 'text': ['to facts is n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                 question  \\\n",
       "32666  32666  What is the main point?   \n",
       "23354  23354  What is the main point?   \n",
       "28625  28625  What is the main point?   \n",
       "\n",
       "                                                 context  \\\n",
       "32666  C.S . Lewis also pointed out that even our abi...   \n",
       "23354  Wait a minute , I fail to see how it not being...   \n",
       "28625  Why do suppose exaggeration and embellishment ...   \n",
       "\n",
       "                                                 answers  \n",
       "32666  {'answer_start': [34], 'text': ['even our abil...  \n",
       "23354  {'answer_start': [0], 'text': ['Wait a minute ...  \n",
       "28625  {'answer_start': [61], 'text': ['to facts is n...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['question'] = 'What is the main point?'\n",
    "df_train['context'] = df_train['q'] + df_train['r']\n",
    "df_train['id'] = df_train.index\n",
    "\n",
    "# calculate the answer index in the context\n",
    "df_train['answers_start'] = df_train[['q', 'q\\'']].apply(lambda x: x['q'].find(x['q\\'']), axis=1)\n",
    "df_train['answers_text'] = df_train['q\\'']\n",
    "df_train['answers'] = df_train[['answers_start', 'answers_text']].apply(lambda x: {'answer_start': [x['answers_start']], 'text': [x['answers_text']]}, axis=1)\n",
    "\n",
    "# drop unmatched answers (results from uncleaned dataset)\n",
    "unmatch_idx = df_train['answers_start'] == -1\n",
    "df_train = df_train[~unmatch_idx]\n",
    "\n",
    "# FIXME: drop length > 360\n",
    "df_train = df_train[(df_train['question']+df_train['context']).apply(lambda x: len(x)) < 360]\n",
    "\n",
    "print(f'Num of unmatch data {unmatch_idx.sum()}')\n",
    "df_train.sample(3)\n",
    "\n",
    "df_train[['id', 'question', 'context', 'answers']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the question + context:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    10520.000000\n",
       "mean       237.915875\n",
       "std         74.205776\n",
       "min         35.000000\n",
       "25%        182.750000\n",
       "50%        243.000000\n",
       "75%        299.000000\n",
       "max        359.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Length of the question + context:')\n",
    "(df_train['question'] + df_train['context']).apply(lambda x: len(x)).describe()\n",
    "# plotly.plot((df_train['question'] + df_train['context']).apply(lambda x: len(x)).sort_values(ascending=False), kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 7364\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 3156\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df_train[['id', 'question', 'context', 'answers']])\n",
    "dataset = dataset.shuffle(seed=42).train_test_split(test_size=0.3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面大多是 copy-paste，可以去看 [Hugging Face Course - Question answering](https://huggingface.co/course/chapter7/7?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:01<00:00,  4.83ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7364, 7364)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "len(dataset[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:00<00:00,  4.31ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3156, 3156)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = dataset[\"test\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    ")\n",
    "len(dataset[\"test\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 7364\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
      "    num_rows: 3156\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/alan/dm/venv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7364\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2763\n",
      "  Number of trainable parameters = 66364418\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2763' max='2763' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2763/2763 04:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.077600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.485000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.304800</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3156\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to test_trainer/checkpoint-1500\n",
      "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3156\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2000\n",
      "Configuration saved in test_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to test_trainer/checkpoint-2500\n",
      "Configuration saved in test_trainer/checkpoint-2500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3156\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2763, training_loss=1.552578572988769, metrics={'train_runtime': 262.6554, 'train_samples_per_second': 84.11, 'train_steps_per_second': 10.519, 'total_flos': 2164791214430208.0, 'train_loss': 1.552578572988769, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "args = TrainingArguments(\n",
    "  'test_trainer/',\n",
    "  evaluation_strategy = \"epoch\",\n",
    "  learning_rate=2e-5,\n",
    "  per_device_train_batch_size=BATCH_SIZE,\n",
    "  per_device_eval_batch_size=BATCH_SIZE,\n",
    "  num_train_epochs=3,\n",
    "  weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?ba/s]\n"
     ]
    }
   ],
   "source": [
    "small_eval_set = dataset[\"test\"].select(range(50))\n",
    "\n",
    "eval_set = small_eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(eval_set):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "for example in small_eval_set:\n",
    "    example_id = example[\"id\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = []\n",
    "\n",
    "    for feature_index in example_to_features[example_id]:\n",
    "        start_logit = start_logits[feature_index]\n",
    "        end_logit = end_logits[feature_index]\n",
    "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
    "\n",
    "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Skip answers that are not fully in the context\n",
    "                if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                    continue\n",
    "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                if (\n",
    "                    end_index < start_index\n",
    "                    or end_index - start_index + 1 > max_answer_length\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                answers.append(\n",
    "                    {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_answers = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  '' infer ( an unknown ) from something that is known ; conjecture. ``and a conjecture is ;\n",
      "Predicted answer:  infer ( an unknown ) from something that is known ; conjecture. ``\n",
      "Correct answer:  infer ( an unknown ) from something that is known ;\n",
      "\n",
      "Context:  While I again feel that it should be assumed he would do so to begin with , I can agree that a simple answer as you say would have been easy enough .You accuse others of making an assumption to the answer . But then you admit that YOU think the answer should have been assumed . Do you see a problem here ?\n",
      "Predicted answer:  I can agree that a simple answer as you say would have been easy enough .\n",
      "Correct answer:  While I again feel that it should be assumed he would do so to begin with\n",
      "\n",
      "Context:  I 'm wondering what it implies that God brought each of the animals to Adam and none of them proved to be a suitable `` helper. `` What exactly does that mean , given the activities that seem to have been carried on between Adam and his proper `` helper `` , Eve ?What ? !\n",
      "Predicted answer:  God brought each of the animals to Adam and none of them proved to be a suitable `` helper. ``\n",
      "Correct answer:  What exactly does that mean , given the activities that seem to have been carried on between Adam and his proper `` helper `` , Eve ?\n",
      "\n",
      "Context:  And I personally wo n't believe anything off of a site like that , nor would I believe anything that I got off a site that was blatantly anti-creationism .Well , where else is the information going to come from ? Nobody else cares about the creation vs. evolution debate except for creationists and evolutionists .\n",
      "Predicted answer:  And I personally wo n't believe anything off of a site like that\n",
      "Correct answer:  And I personally wo n't believe anything off of a site like that , nor would I believe anything that I got off a site that was blatantly anti-creationism\n",
      "\n",
      "Context:  WHAT ? I do n't see anything regarding that . Seriously , what are you talking about ?Look again .\n",
      "Predicted answer:  I do n't see anything regarding that .\n",
      "Correct answer:  WHAT ? I do n't see anything regarding that . Seriously , what are you talking about ?\n",
      "\n",
      "Context:  You have this odd notion that only the Biblical faiths count as religions .No i dont ... as im a plurilist ....\n",
      "Predicted answer:  You have this odd notion that only the Biblical faiths count as religions .\n",
      "Correct answer:  only the Biblical faiths count as religions .\n",
      "\n",
      "Context:  But the question is pretty irrelevant to scienceReally ? Then why do they experiment on `` antigravity `` devices or the theoretical possibility of `` time-travel `` ?\n",
      "Predicted answer:  But the question is pretty irrelevant to science\n",
      "Correct answer:  But the question is pretty irrelevant to science\n",
      "\n",
      "Context:  Simple and insightful , I agree . I wonder what EZ thinks ?I think dropping trou for illicit gay sex has nothing to do with genes . It 's a deliberate behavior .\n",
      "Predicted answer:  Simple and insightful , I agree . I wonder what EZ thinks ?\n",
      "Correct answer:  Simple and insightful , I agree\n",
      "\n",
      "Context:  A gunman killed at least 12 people in a shooting spree in Cumbria and injured another 25 before taking his own life .Top that .\n",
      "Predicted answer:  A gunman killed at least 12 people in a shooting spree in Cumbria and injured another 25 before taking his own life .\n",
      "Correct answer:  A gunman killed at least 12 people in a shooting spree in Cumbria and injured another 25 before taking his own life\n",
      "\n",
      "Context:  1+1=2 if we know the meaning or notThank you for repeating me .\n",
      "Predicted answer:  1+1=2 if we know the meaning or not\n",
      "Correct answer:  1+1=2 if we know the meaning or not\n",
      "\n",
      "Context:  What is shown very clearly from all of these scientific interpretation of the same evidence is that there are two ways to interpret it .Unfortunately for you , that is not shown , the evidence points in one direction , and one direction only . That of evolution and to the fact that the flood never happened .\n",
      "Predicted answer:  What is shown very clearly from all of these scientific interpretation of the same evidence is that there are two ways to interpret it .\n",
      "Correct answer:  What is shown very clearly from all of these scientific interpretation of the same evidence is that there are two ways to interpret it .\n",
      "\n",
      "Context:  Be that as it may , no one has refuted that there are more cases of Concealed Carry Permit holders who have gone off and assaulted people than there have been school shootings .And there have been more cases of people being killed with knives than so called `` assault weapons `` . Your point is what ?\n",
      "Predicted answer:  no one has refuted that there are more cases of Concealed Carry Permit holders who have gone off and assaulted people than there have been school shootings .\n",
      "Correct answer:  no one has refuted that there are more cases\n",
      "\n",
      "Context:  The whole who is on top thing is an inapplicable concept .* * But here you blow it . No system , as a whole , is subservient , subordinate , inferior , or secondary to any or all of its parts . By simple definition a whole system is greater than , and superior to , any and all of its constituent parts .\n",
      "Predicted answer:  The whole who is on top thing is an inapplicable concept .\n",
      "Correct answer:  The whole who is on top thing is an inapplicable concept .\n",
      "\n",
      "Context:  And as such , the term as you use it is utterly meaningless as it could be applied to any cell or sell remnant of human origin .And we agree that it is a physical entity ... the same as any cell of human origin ... in fact , the same as anything else that exists in the physical world . We 're two-for-two .\n",
      "Predicted answer:  the term as you use it is utterly meaningless as it could be applied to any cell or sell remnant of human origin .\n",
      "Correct answer:  the term as you use it is utterly meaningless as it could be applied to any cell or sell remnant of human origin .\n",
      "\n",
      "Context:  `` The gun lobby , however , didnÂ ’ t count on an uprising among African-Americans in Congress who favor gun control .Oh really ? And who are these people ? Point them out to us .\n",
      "Predicted answer:  The gun lobby , however , didnÂ ’ t count on an uprising among African-Americans in Congress who favor gun control .\n",
      "Correct answer:  The gun lobby , however , didnÂ ’ t count on an uprising among\n",
      "\n",
      "Context:  My point was to ask you a question . Why do you call it revisionist history ?Your implication that dropping crime rates has anything to do with the AWB ....\n",
      "Predicted answer:  My point was to ask you a question . Why do you call it revisionist history ?\n",
      "Correct answer:  Why do you call it revisionist history ?\n",
      "\n",
      "Context:  put a damper on my support of gay rights .But maybe god does not hate gays , maybe he just hates the ones that demand to have sex with people whether they want it or not .\n",
      "Predicted answer:  put a damper on my support of gay rights .\n",
      "Correct answer:  put a damper on my support of gay rights .\n",
      "\n",
      "Context:  For two thousand years the bible has been disputed yet it still stands .What do you mean by 'Yet it still stands ' ? Are you saying that it has ultimate authority , or it is simply a cultural fairy tale that so many are frightened to discard ?\n",
      "Predicted answer:  For two thousand years the bible has been disputed yet it still stands .\n",
      "Correct answer:  has been disputed yet it still stands .\n",
      "\n",
      "Context:  If DOMA is n't declared unconstitutional , then those arguing against Prop 8 are micturating into the wind .Oh dear God your ignorance is abundant ! Do you not understand what the federal DOMA law does ?\n",
      "Predicted answer:  If DOMA is n't declared unconstitutional , then those arguing against Prop 8 are micturating into the wind .\n",
      "Correct answer:  If DOMA is n't declared unconstitutional ,\n",
      "\n",
      "Context:  Including I suppose the underling of the same words in both places ?so where is the evolution ?\n",
      "Predicted answer:  Including I suppose the underling of the same words in both places ?\n",
      "Correct answer:  Including I suppose the underling of the same words in both places ?\n",
      "\n",
      "Context:  That would be beating the bejesus out of a kid as opposed to teaching him or her how to govern his or her impulses by themselves .Like you were raised ? Looks like it did n't work and now those hormones must be kicking in ? Nothing worse than a menopausal female grinding her ax ... their favorite victims ? Males .\n",
      "Predicted answer:  That would be beating the bejesus out of a kid as opposed to teaching him or her how to govern his or her impulses by themselves .\n",
      "Correct answer:  how to govern his or her impulses\n",
      "\n",
      "Context:  ( 2 ) : the state of being united to a person of the same sex in a relationship like that of a traditional marriage < same-sex marriage >Dictionary.com http : //dictionary.reference.com/browse/marriage\n",
      "Predicted answer:  the state of being united to a person of the same sex in a relationship like that of a traditional marriage\n",
      "Correct answer:  the state of being united to a person of the same sex in a relationship like that of a traditional marriage\n",
      "\n",
      "Context:  After all , unfertilized eggs and sperm also have the * potential * to become full people but no one is concerned about their loss . For many of us it is the actual mentally-existing person that is most important .An unfertilized egg or sperm alone will not grow up into a person . So it does NOT have that potential at all .\n",
      "Predicted answer:  unfertilized eggs and sperm also have the * potential * to become full people but no one is concerned about their loss .\n",
      "Correct answer:  unfertilized eggs and sperm also have the * potential * to become full people but no one is concerned about their loss\n",
      "\n",
      "Context:  Was the snake actually a snake or is it a metaphor ?You must be assuming that the entire story is true . Again , how can anyone possibly answer this ?\n",
      "Predicted answer:  Was the snake actually a snake or is it a metaphor ?\n",
      "Correct answer:  Was the snake actually a snake or is it a metaphor ?\n",
      "\n",
      "Context:  ID [ intelligent design ] says that , get your arguments straight ,No , the `` life ex nihilo `` doctrine of YE also denies God 's word in Genesis .\n",
      "Predicted answer:  ID [ intelligent design ] says that , get your arguments straight ,\n",
      "Correct answer:  ID [ intelligent design ] says that , get your arguments straight\n",
      "\n",
      "Context:  Why worship god ? Please ! No scripture .Upon what basis would discussion be acceptable if not scripture ? If we are to debat the topic , what sources for informational purposes do you consider as `` authoritative `` ? EF\n",
      "Predicted answer:  Why worship god ?\n",
      "Correct answer:  No scripture .\n",
      "\n",
      "Context:  This is clearly the worst one . Mr. Harvey shows his ignorance and dislike of science .So what if he dislikes science ? If he believes something else , he has the right to believe that way . My problem here is that he shows more closed-mindedness to the viewpoints of others .\n",
      "Predicted answer:  Mr. Harvey shows his ignorance and dislike of science .\n",
      "Correct answer:  This is clearly the worst one . Mr. Harvey shows his ignorance and dislike of science .\n",
      "\n",
      "Context:  How can you tell the difference ?Excellent point Doc\n",
      "Predicted answer:  How can you tell the difference ?\n",
      "Correct answer:  How can you tell the difference ?\n",
      "\n",
      "Context:  Um , no . There are many man-made substances that are not found in nature at all . And , I 've never seen one of those naturally occuring skyscrapers or Ford F-150 's .But what makes them any different from ant hills or beaver dams ? skyscrapers are natural because humans are a part of nature and they built them .\n",
      "Predicted answer:  There are many man-made substances that are not found in nature at all .\n",
      "Correct answer:  There are many man-made substances that are not found in nature at all .\n",
      "\n",
      "Context:  BUT along come a man-made invention that allows those certain portions to live on , and survive . In once case - nylon , the other , the artifical heart . You call this evolution .What does a mutation have to do with a heart transplant ? What are you smoking ?\n",
      "Predicted answer:  BUT along come a man-made invention that allows those certain portions to live on , and survive .\n",
      "Correct answer:  BUT along come a man-made invention that allows those certain portions to live on , and survive . In once case - nylon , the other , the artifical heart . You call this evolution .\n",
      "\n",
      "Context:  Have we ever seen an example of life emerging from a sterile , lifeless environment ?Replicating molecules and lipid membranes have arisen spontaneously in the lab . Functioning viruses have been created from the correct sequencing of nucleic acids . Besides , what are you talking about ?\n",
      "Predicted answer:  Have we ever seen an example of life emerging from a sterile , lifeless environment ?\n",
      "Correct answer:  Have we ever seen an example of life emerging from a sterile , lifeless environment ?\n",
      "\n",
      "Context:  without abiogenesis proven evolution can not be proven .See above , yet again\n",
      "Predicted answer:  without abiogenesis proven evolution can not be proven .\n",
      "Correct answer:  without abiogenesis proven evolution can not be proven .\n",
      "\n",
      "Context:  Um , no . There are many man-made substances that are not found in nature at all . And , I 've never seen one of those naturally occuring skyscrapers or Ford F-150 's .But what makes them any different from ant hills or beaver dams ? skyscrapers are natural because humans are a part of nature and they built them .\n",
      "Predicted answer:  There are many man-made substances that are not found in nature at all .\n",
      "Correct answer:  I 've never seen one of those naturally occuring skyscrapers\n",
      "\n",
      "Context:  A person that has blacked out due to drinking wo n't remember but they still had an experience .. but , as I said , this does n't matter .But what would he have learned from it ? If you 're going to use that analogy , then lets say the last thing he remembers is walking to the bar . What would he learn or have experienced ?\n",
      "Predicted answer:  A person that has blacked out due to drinking wo n't remember but they still had an experience\n",
      "Correct answer:  A person that has blacked out due to drinking wo n't remember but they still had an experience\n",
      "\n",
      "Context:  3 . Therefore abortion is wrong .Nope .\n",
      "Predicted answer:  Therefore abortion is wrong .\n",
      "Correct answer:  Therefore abortion is wrong .\n",
      "\n",
      "Context:  I was about to take a sip of coffee when I read that ! Would have lost the keyboard and monitor ! ! !Sarge you getten up with the birds again ? or do old habits just die hard ? 3:30 every morning here .\n",
      "Predicted answer:  I was about to take a sip of coffee when I read that ! Would have lost the keyboard and monitor ! ! !\n",
      "Correct answer:  Would have lost the keyboard and monitor ! ! !\n",
      "\n",
      "Context:  What are you counting as critical ? Stats ?Heart bypass , prostate cancer ....... I have a couple of Canadian friends who needed those surgeries and one was told he had a 4 month wait and the other a 6 month wait so they both came down to Bellingham Wash and had the Surgery within 2 weeks ............\n",
      "Predicted answer:  What are you counting as critical ?\n",
      "Correct answer:  What are you counting as critical ? Stats ?\n",
      "\n",
      "Context:  I simply wanted to point out that pregnancy can kill a woman . Guess you just could n't understand that .No one said otherwise and it is still irrelevant .\n",
      "Predicted answer:  I simply wanted to point out that pregnancy can kill a woman .\n",
      "Correct answer:  wanted to point out that pregnancy can kill a woman .\n",
      "\n",
      "Context:  I am a little unclear about Harbingers statements . Are you saying it is ok for the mother to murder something that is inside of her ?Well Steve `` murder `` is a legal term that does not apply in abortion . But for the sake of keeping this simple - yes , and not only that , it 's legal .\n",
      "Predicted answer:  Are you saying it is ok for the mother to murder something that is inside of her ?\n",
      "Correct answer:  I am a little unclear about Harbingers statements . Are you saying it is ok for the mother to murder something that is inside of her ?\n",
      "\n",
      "Context:  Come on now . That 's a bit simplistic , is n't it ? Drop a hottie between those same college boys and watch the testosterone at work there . Lots of things can make men aggressive .If they really like women . It 's not totally clear that Bush `` likes `` woman .\n",
      "Predicted answer:  Come on now . That 's a bit simplistic , is n't it ?\n",
      "Correct answer:  things can make men aggressive\n",
      "\n",
      "Context:  human : A member of the genus Homo and especially of the species H. sapiens .Well , the unborn qualifies for this ... so we can conclude , using YOUR logic , that the unborn ... from conception on .... is , in fact , a human being . You can remove the foot from your mouth now .\n",
      "Predicted answer:  human : A member of the genus Homo and especially of the species H. sapiens .\n",
      "Correct answer:  human : A member of the genus Homo\n",
      "\n",
      "Context:  That 's why you do n't find them much below the Arctic circle . Anyway , the change still is n't evolution . That 's my claimWhat 's your claim ? That the seasonal molt of arctic foxes is evolution or that it is not ? As usual , your responses show muddled thinking .\n",
      "Predicted answer:  That 's why you do n't find them much below the Arctic circle .\n",
      "Correct answer:  That 's why you do n't find them much below the Arctic circle . Anyway , the change still is n't evolution . That 's my claim\n",
      "\n",
      "Context:  Matt , you 're so dramatic sometimes .Really ?\n",
      "Predicted answer:  Matt , you 're so dramatic sometimes .\n",
      "Correct answer:  Matt , you 're so dramatic sometimes .\n",
      "\n",
      "Context:  I would be interested in know who was the first creationist to finally accept that natural selection is a real phenomenon , and when they accepted it . I do n't know his name , but I 'll research it for you and tell you in a week or so .My bet is that it wo n't be natural selection .\n",
      "Predicted answer:  I would be interested in know who was the first creationist to finally accept that natural selection is a real phenomenon ,\n",
      "Correct answer:  I would be interested in know who was the first creationist to finally accept that natural selection is a real phenomenon\n",
      "\n",
      "Context:  I invite you to compare that list to the Steve list , now at 720+ scientists named Steve who accept evolution as the correct explanation for the observed diversity of life .As of this post , Project Steve stands at 703 Steves . The Steve-o-Meter 's visual representation is a little misleading .\n",
      "Predicted answer:  now at 720+ scientists named Steve who accept evolution as the correct explanation for the observed diversity of life .\n",
      "Correct answer:  Steve list , now at 720+ scientists named Steve\n",
      "\n",
      "Context:  Yes , it is interesting how we draw an arbitary `` legal line in the sand `` with regards to determining how late into a pregnancy an elective abortion is available .But how can we make rules without legal lines in sand ? At least its better than an illegal line .\n",
      "Predicted answer:  determining how late into a pregnancy an elective abortion is available .\n",
      "Correct answer:  it is interesting how we draw an arbitary `` legal line in the sand ``\n",
      "\n",
      "Context:  Not a coincidence , just a stupid population to look at to understand whether marijuana does or does not lead to `` harder `` drugs . And the word of some guy you heard about is how you draw conclusions ?Oh , so this only happens here , huh ? Every single hardcore drug addict is here , huh ?\n",
      "Predicted answer:  Not a coincidence , just a stupid population to look at to understand whether marijuana does or does not lead to `` harder `` drugs .\n",
      "Correct answer:  marijuana does or does not lead to `` harder `` drugs . And the word of some guy you heard\n",
      "\n",
      "Context:  religious : relating to or manifesting faithful devotion to an acknowledged ULTIMATE REALITY or dietyAtheism does not show 'faithful devotion ' in any ultimate reality or deity . It is the LACK of a belief ( the belief in gods ) . Your definition of religion is thin .\n",
      "Predicted answer:  relating to or manifesting faithful devotion to an acknowledged ULTIMATE REALITY or dietyAt\n",
      "Correct answer:  religious : relating to or manifesting faithful devotion to an acknowledged ULTIMATE REALITY or diety\n",
      "\n",
      "Context:  You have much to learn , my young padawan .As do you .\n",
      "Predicted answer:  You have much to learn , my young padawan .\n",
      "Correct answer:  You have much to learn , my young padawan .\n",
      "\n",
      "Context:  My point exactly . Carbon dating is by no means accurate , there it does not refute creationism .How does it not refute creationism ? Creationism states that the world is 7,000 years old . Carbon dating is only accurate up to a point , and that point is WELL beyond creationism 's statements .\n",
      "Predicted answer:  Carbon dating is by no means accurate , there it does not refute creationism .\n",
      "Correct answer:  creationism\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(\"Context: \", small_eval_set[i][\"context\"])\n",
    "    print(\"Predicted answer: \", predicted_answers[i][\"prediction_text\"])\n",
    "    print(\"Correct answer: \", theoretical_answers[i][\"answers\"][\"text\"][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd18ad61a764f50ef87415555d6b20bbe826f43f65518458ad3ed025fdd4cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
