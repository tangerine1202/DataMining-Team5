{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import get_scheduler, DefaultDataCollator\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "PRETRAINED_MODEL_NAME = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    29600\n",
      "1     6415\n",
      "Name: s_label, dtype: int64\n",
      "# of distinct data:\t 7987\n",
      "# of data:\t 36015\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>q'</th>\n",
       "      <th>r'</th>\n",
       "      <th>s_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16463</th>\n",
       "      <td>4634</td>\n",
       "      <td>Early Christian authorities rejected marriage ...</td>\n",
       "      <td>Freethought Today , November 2008</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>Early Christian authorities rejected marriage ...</td>\n",
       "      <td>Freethought Today , November 2008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35687</th>\n",
       "      <td>9932</td>\n",
       "      <td>Many Christians often say that the proofs for ...</td>\n",
       "      <td>Just because the bible is over 2000 years old ...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>Many Christians often say that the proofs for ...</td>\n",
       "      <td>You do n't have any absolute proof and neither...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10486</th>\n",
       "      <td>2935</td>\n",
       "      <td>I 'm now slightly less confused about why I 'v...</td>\n",
       "      <td>Do me a favor . Write , in your own words , tw...</td>\n",
       "      <td>DISAGREE</td>\n",
       "      <td>I 'm now slightly less confused</td>\n",
       "      <td>Write , in your own words , two paragraphs . O...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                                  q  \\\n",
       "16463  4634  Early Christian authorities rejected marriage ...   \n",
       "35687  9932  Many Christians often say that the proofs for ...   \n",
       "10486  2935  I 'm now slightly less confused about why I 'v...   \n",
       "\n",
       "                                                       r         s  \\\n",
       "16463                  Freethought Today , November 2008  DISAGREE   \n",
       "35687  Just because the bible is over 2000 years old ...  DISAGREE   \n",
       "10486  Do me a favor . Write , in your own words , tw...  DISAGREE   \n",
       "\n",
       "                                                      q'  \\\n",
       "16463  Early Christian authorities rejected marriage ...   \n",
       "35687  Many Christians often say that the proofs for ...   \n",
       "10486                    I 'm now slightly less confused   \n",
       "\n",
       "                                                      r'  s_label  \n",
       "16463                  Freethought Today , November 2008        0  \n",
       "35687  You do n't have any absolute proof and neither...        0  \n",
       "10486  Write , in your own words , two paragraphs . O...        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/Batch_answers - train_data (no-blank).csv' )\n",
    "\n",
    "# drop unnecessary columns\n",
    "df_train = df_train.drop(['Unnamed: 6', 'total no.: 7987'], axis=1)\n",
    "\n",
    "# remove quotes\n",
    "df_train['q'] = df_train['q'].str.strip('\"')\n",
    "df_train['r'] = df_train['r'].str.strip('\"')\n",
    "df_train[\"q'\"] = df_train[\"q'\"].str.strip('\"')\n",
    "df_train[\"r'\"] = df_train[\"r'\"].str.strip('\"')\n",
    "\n",
    "# drop duplicated rows\n",
    "df_train = df_train.drop_duplicates()\n",
    "\n",
    "# numerical s\n",
    "df_train['s_label'] = (df_train['s'] == 'AGREE').astype(int)\n",
    "\n",
    "# some information about the dataset\n",
    "print(df_train['s_label'].value_counts())\n",
    "print('# of distinct data:\\t', len(df_train['id'].unique()))\n",
    "print('# of data:\\t', len(df_train))\n",
    "\n",
    "# save cleaned dataset\n",
    "df_train.to_csv('data/train.tsv', sep='\\t', index=False)\n",
    "\n",
    "# load cleaned dataset\n",
    "df_train = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of unmatch data 5865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>u_id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6534</th>\n",
       "      <td>6534</td>\n",
       "      <td>1833</td>\n",
       "      <td>What is the main point?</td>\n",
       "      <td>No , it does n't make it right but it 's not r...</td>\n",
       "      <td>{'answer_start': [5], 'text': ['it does n't ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24311</th>\n",
       "      <td>24311</td>\n",
       "      <td>6819</td>\n",
       "      <td>What is the main point?</td>\n",
       "      <td>TalkOrigins contains nothing but barely readab...</td>\n",
       "      <td>{'answer_start': [0], 'text': ['TalkOrigins co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25978</th>\n",
       "      <td>25978</td>\n",
       "      <td>7225</td>\n",
       "      <td>What is the main point?</td>\n",
       "      <td>It is so easy , so simple , so evident is not ...</td>\n",
       "      <td>{'answer_start': [0], 'text': ['It is so easy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  u_id                 question  \\\n",
       "6534    6534  1833  What is the main point?   \n",
       "24311  24311  6819  What is the main point?   \n",
       "25978  25978  7225  What is the main point?   \n",
       "\n",
       "                                                 context  \\\n",
       "6534   No , it does n't make it right but it 's not r...   \n",
       "24311  TalkOrigins contains nothing but barely readab...   \n",
       "25978  It is so easy , so simple , so evident is not ...   \n",
       "\n",
       "                                                 answers  \n",
       "6534   {'answer_start': [5], 'text': ['it does n't ma...  \n",
       "24311  {'answer_start': [0], 'text': ['TalkOrigins co...  \n",
       "25978  {'answer_start': [0], 'text': ['It is so easy ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['question'] = 'What is the main point?'\n",
    "df_train['context'] = df_train['q'] + df_train['r']\n",
    "df_train['u_id'] = df_train['id']\n",
    "df_train['id'] = df_train.index\n",
    "\n",
    "# calculate the answer index in the context\n",
    "df_train['answers_start'] = df_train[['q', 'q\\'']].apply(lambda x: x['q'].find(x['q\\'']), axis=1)\n",
    "df_train['answers_text'] = df_train['q\\'']\n",
    "df_train['answers'] = df_train[['answers_start', 'answers_text']].apply(lambda x: {'answer_start': [x['answers_start']], 'text': [x['answers_text']]}, axis=1)\n",
    "\n",
    "# drop unmatched answers (results from uncleaned dataset)\n",
    "unmatch_idx = df_train['answers_start'] == -1\n",
    "df_train = df_train[~unmatch_idx]\n",
    "\n",
    "# FIXME: drop length > 360\n",
    "df_train = df_train[(df_train['question']+df_train['context']).apply(lambda x: len(x)) < 360]\n",
    "\n",
    "print(f'Num of unmatch data {unmatch_idx.sum()}')\n",
    "df_train.sample(3)\n",
    "\n",
    "df_train[['id', 'u_id', 'question', 'context', 'answers']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the question + context:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    10520.000000\n",
       "mean       237.915875\n",
       "std         74.205776\n",
       "min         35.000000\n",
       "25%        182.750000\n",
       "50%        243.000000\n",
       "75%        299.000000\n",
       "max        359.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Length of the question + context:')\n",
    "(df_train['question'] + df_train['context']).apply(lambda x: len(x)).describe()\n",
    "# plotly.plot((df_train['question'] + df_train['context']).apply(lambda x: len(x)).sort_values(ascending=False), kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 7364\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 3156\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df_train[['id', 'question', 'context', 'answers']])\n",
    "dataset = dataset.shuffle(seed=42).train_test_split(test_size=0.3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面大多是 copy-paste，可以去看 [Hugging Face Course - Question answering](https://huggingface.co/course/chapter7/7?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade2a0291d614645a95e2e38ff39c404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7364, 7364)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "len(dataset[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5dacca264548c9b95a1693b10f0624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3156, 3156)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = dataset[\"test\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    ")\n",
    "len(dataset[\"test\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 7364\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
      "    num_rows: 3156\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/arui/dm/dm_venv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7364\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2763\n",
      "  Number of trainable parameters = 66364418\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2763' max='2763' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2763/2763 11:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.060400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.480600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.322200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3156\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to test_trainer/checkpoint-1500\n",
      "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3156\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-2000\n",
      "Configuration saved in test_trainer/checkpoint-2000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to test_trainer/checkpoint-2500\n",
      "Configuration saved in test_trainer/checkpoint-2500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in test_trainer/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in test_trainer/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3156\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2763, training_loss=1.546786584070615, metrics={'train_runtime': 706.0777, 'train_samples_per_second': 31.288, 'train_steps_per_second': 3.913, 'total_flos': 2164791214430208.0, 'train_loss': 1.546786584070615, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "args = TrainingArguments(\n",
    "  'test_trainer/',\n",
    "  evaluation_strategy = \"epoch\",\n",
    "  learning_rate=2e-5,\n",
    "  per_device_train_batch_size=BATCH_SIZE,\n",
    "  per_device_eval_batch_size=BATCH_SIZE,\n",
    "  num_train_epochs=3,\n",
    "  weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942f72d07cfb4080b9600e4540c253a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_eval_set = dataset[\"test\"].select(range(50))\n",
    "\n",
    "eval_set = small_eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(eval_set):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "for example in small_eval_set:\n",
    "    example_id = example[\"id\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = []\n",
    "\n",
    "    for feature_index in example_to_features[example_id]:\n",
    "        start_logit = start_logits[feature_index]\n",
    "        end_logit = end_logits[feature_index]\n",
    "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
    "\n",
    "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Skip answers that are not fully in the context\n",
    "                if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                    continue\n",
    "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                if (\n",
    "                    end_index < start_index\n",
    "                    or end_index - start_index + 1 > max_answer_length\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                answers.append(\n",
    "                    {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_answers = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  So it 's not evidence vs evidence , it 's evidence vs religious belief .Well , youÂ ’ re just begging the question of what is evidence . You are saying religious belief ( others might say religious knowledge ) is not evidence . If it is scientific , it is evidence . If it is not scientific , it is not evidence . Have I got it right ?\n",
      "Predicted answer:  So it 's not evidence vs evidence , it 's evidence vs religious belief .\n",
      "Correct answer:  So it 's not evidence vs evidence , it 's evidence vs religious belief .\n",
      "\n",
      "Context:  So it would be more loving to severely beat the child ... forever ?A person going to Hell is a consequence of sin . God does n't want it , but he ca n't stop it .\n",
      "Predicted answer:  So it would be more loving to severely beat the child ... forever ?\n",
      "Correct answer:  it would be more loving to severely beat the child ... forever ?\n",
      "\n",
      "Context:  We 've been over this many many times before ...And you continually refuse to learn the facts of the matter .\n",
      "Predicted answer:  We 've been over this many many times before ...\n",
      "Correct answer:  We 've been over this many many times before\n",
      "\n",
      "Context:  a pro-gunner with the SN of `` marxismismurder `` conservative was a pretty safe bet . You do n't see many liberals in that mold .I believe in a strict interpretation of the Constitution , this makes me neither a liberal or conservative . The SN was inspired by VOR who kept signing his posts with quotes from Karl Marx .\n",
      "Predicted answer:  a pro-gunner with the SN of `` marxismismurder `` conservative was a pretty safe bet .\n",
      "Correct answer:  a pro-gunner with the SN of `` marxismismurder `` conservative was a pretty safe bet . You do n't see many liberals in that mold .\n",
      "\n",
      "Context:  If you disagree with them , you are branded as a religious zealot who 's determined to take their rights away .So try actually responding to the points I 'm making rather than just making up stuff to attack me over .\n",
      "Predicted answer:  If you disagree with them , you are branded as a religious zealot who 's determined to take their rights away .\n",
      "Correct answer:  their rights away\n",
      "\n",
      "Context:  1 ) All organisms tend to produce more offspring than can possibly survive .False and that does n't invalide evolution given how it 's a misrepresentation of one of the statements in the theory . Gould can take his comments and shove them up his * * * .\n",
      "Predicted answer:  All organisms tend to produce more offspring than can possibly survive .\n",
      "Correct answer:  All organisms tend to produce more offspring than can possibly survive .\n",
      "\n",
      "Context:  Because it 's unfair that us little people can also own guns .I pretend I 'm rich and famous that way being surrounded by firepower do n't bother me as much and I feel better about it .\n",
      "Predicted answer:  Because it 's unfair that us little people can also own guns .\n",
      "Correct answer:  it 's unfair that us little people can also own guns .\n",
      "\n",
      "Context:  This , of course , blows away Hi_Its_Me 's attempts to make evolution atheistic .You mean marc 's ? I never tried to do that .\n",
      "Predicted answer:  This , of course , blows away Hi_Its_Me 's attempts to make evolution atheistic .\n",
      "Correct answer:  's attempts to make evolution atheistic .\n",
      "\n",
      "Context:  Well if it saves my life what is the problem ? ? Are n't we pro life here ? ? ? ? ?It is much more important that you concern yourself with the destiny of your soul , not how many years you can stay on the earth .\n",
      "Predicted answer:  Well if it saves my life what is the problem\n",
      "Correct answer:  if it saves my life what is the problem ? ?\n",
      "\n",
      "Context:  There is not a shred of evidence that life came into being by only natural processes .But there is no evidence that it did not come about by natural processes . And , there is , in fact , evidence of natural processes that may have resulted in life . Just because you do n't understand it does n't make it so .\n",
      "Predicted answer:  There is not a shred of evidence that life came into being by only natural processes .\n",
      "Correct answer:  not a shred of evidence that life came into being by only natural processes .\n",
      "\n",
      "Context:  Here is what I define evolution as : Evolution is a three part theory ,Actually , it is n't .\n",
      "Predicted answer:  Here is what I define evolution as : Evolution is a three part theory ,\n",
      "Correct answer:  Evolution is a three part theory ,\n",
      "\n",
      "Context:  Oh come on , marc , you ca n't possibly expect me to swallow that one . Religion , which locked up astronomers ?Churches are not locking up astronomers today !\n",
      "Predicted answer:  Oh come on , marc , you ca n't possibly expect me to swallow that one .\n",
      "Correct answer:  Oh come on , marc , you ca n't possibly expect me to swallow that one . Religion , which locked up astronomers ?\n",
      "\n",
      "Context:  I wish they HAD arrested him ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !Oh I 've got no doubt that you do , and that you wish much worse on him than that as well .\n",
      "Predicted answer:  I wish they HAD arrested him ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "Correct answer:  I wish they HAD arrested him !\n",
      "\n",
      "Context:  The problem with this is that usually when someone exercises `` their right `` it many times infringes on someones elses rights .Do n't even think about contriving how gay marrige violates YOUR RIGHTS assmonkey . That 's the most ludicrous , inane statement I have yet heard from the Religious Right .\n",
      "Predicted answer:  The problem with this is that usually when someone exercises `` their right `` it many times infringes on someones elses rights .\n",
      "Correct answer:  The problem with this is that usually when someone exercises `` their right `` it many times infringes on someones elses rights .\n",
      "\n",
      "Context:  Wow that must really suck for those couplesWell the blame falls to the county for issuing illegal marriage licenses . Such is the price for acting outside the law .\n",
      "Predicted answer:  Wow that must really suck for those couples\n",
      "Correct answer:  Wow that must really suck for those couples\n",
      "\n",
      "Context:  i will pray for you all right nowDo n't pray for us ! Debate with us ! Are all your posts so pointless ?\n",
      "Predicted answer:  i will pray for you all right now\n",
      "Correct answer:  i will pray for you all\n",
      "\n",
      "Context:  I do not wish to appear to dispute this , but do you have a reference for this claim as it is very interesting ? Thank you .Stuff I picked up in Uni , along with the Human genetic code being 40 % identical to a banana ... so no specific reference , sorry .\n",
      "Predicted answer:  I do not wish to appear to dispute this , but do you have a reference for this claim as it is very interesting ?\n",
      "Correct answer:  but do you have a reference for this claim as it is very interesting ?\n",
      "\n",
      "Context:  If we bankrupt the country , the war on terror wo n't be the reason .You 're right it 'll be fighting the war in Iraq . ) Nah , really it 'll be from social security , etc etc .\n",
      "Predicted answer:  If we bankrupt the country , the war on terror wo n't be the reason .\n",
      "Correct answer:  If we bankrupt the country , the war on terror wo n't be the reason\n",
      "\n",
      "Context:  Hunters could trample through Yellowstone or any other national park , guns in hand .YES , of course , they could not actually hunt , since that would be illegal , possibly a felony , whihc could lead to forfeiture of your rights .\n",
      "Predicted answer:  Hunters could trample through Yellowstone or any other national park , guns in hand .\n",
      "Correct answer:  Hunters could trample through Yellowstone or any other national park , guns in hand .\n",
      "\n",
      "Context:  Since they are issued by the military I would think so .But you still feel they have the right idea when it comes to firearms ?\n",
      "Predicted answer:  Since they are issued by the military I would think so .\n",
      "Correct answer:  they are issued by the military\n",
      "\n",
      "Context:  It is just as likely that an alien from uranus landed on premoridalearth , took a dump , and we are all decended from an intergallactic tapeworm .And that is more likely than a magical being who poofed everything from nothing , do n't you agree ?\n",
      "Predicted answer:  It is just as likely that an alien from uranus landed on premoridalearth\n",
      "Correct answer:  It is just as likely that an alien from uranus landed on premoridalearth\n",
      "\n",
      "Context:  Â “ The topic at hand was abortion , not his God.Â ”I donÂ ’ t know if you actually read his/her entire post but God was invoked into it . So why canÂ ’ t I use any reference to God if they are using it ?\n",
      "Predicted answer:  The topic at hand was abortion , not his God.\n",
      "Correct answer:  The topic at hand was abortion , not his\n",
      "\n",
      "Context:  I did n't mention evolution in this topic . You did .Oh , so you were not in any way talking about evolution in these posts ? Then why are they posted on the c vs e board ? Please , that 's just pathetic .\n",
      "Predicted answer:  I did n't mention evolution in this topic .\n",
      "Correct answer:  I did n't mention evolution\n",
      "\n",
      "Context:  There is no evidence either way .No evidence of what ?\n",
      "Predicted answer:  There is no evidence either way .\n",
      "Correct answer:  no evidence either way\n",
      "\n",
      "Context:  The first one is moderately valid ... the rest are straw men .Well then it sounds like you do n't even know what a SM is seeing as the 3rd one is the main one that people like you bring up when debating this isse .\n",
      "Predicted answer:  The first one is moderately valid ... the rest are straw men .\n",
      "Correct answer:  The first one is moderately valid ... the rest are straw men .\n",
      "\n",
      "Context:  Bingo -- and thus without state sovereignty , the Supreme Court is Law : hence Madison 's warning that it would spell the end of Freedom .And it was not the 9th Amendment that the court has used to accomplish this . Rather , it is the 14th through various illegitimate legal doctrines such as incorporation and substantive due process .\n",
      "Predicted answer:  and thus without state sovereignty , the Supreme Court is Law : hence Madison 's warning that it would spell the end of Freedom .\n",
      "Correct answer:  hence Madison 's warning that it would spell the end of Freedom .\n",
      "\n",
      "Context:  I just was impressed that the fossil was not found by happenstance .So was I. I did say I was playing devil 's advocate . As far as I 'm concerned , Tiktaalik is a triumph of scientific deduction .\n",
      "Predicted answer:  I just was impressed that the fossil was not found by happenstance .\n",
      "Correct answer:  I just was impressed that the fossil was not found by happenstance .\n",
      "\n",
      "Context:  Now name one country with universal socialized healthcare with a population of 300 million citizens modulus , just one if you can . Your exemplar countries are tiny in comparison to us so lets get realistic and compare apples to apples for once , ok ?The population of the European Union is 501,259,840 .\n",
      "Predicted answer:  Now name one country with universal socialized healthcare with a population of 300 million citizens modulus , just one if you can .\n",
      "Correct answer:  Your exemplar countries are tiny in comparison to us\n",
      "\n",
      "Context:  bestiality commiters will possibly make similar arguments , since their logic is about the same ( i.e. , not illegal , not hurting anyone else ) , and there will be no surprise if people could marry their pets in the future .But bestiality consists of animal cruelty , so very much hurts another . Just not another human .\n",
      "Predicted answer:  bestiality commiters will possibly make similar arguments , since their logic is about the same\n",
      "Correct answer:  bestiality commiters will possibly make similar arguments , since their logic is about the same ( i.e. , not illegal , not hurting anyone else ) , and there will be no surprise if people could marry their pets in the future .\n",
      "\n",
      "Context:  Originally posted by DarKnight But what is logic other then a dogma with a higher refresher rate ?Well , I would call it a formalized set of rules and procedures for evaluating the validity of propositions . How does that relate to a dogma with a higher refresh rate ? ? ? ? ?\n",
      "Predicted answer:  what is logic other then a dogma with a higher refresher rate ?\n",
      "Correct answer:  what is logic other then a dogma with a higher refresher rate ?\n",
      "\n",
      "Context:  And why is that ?Because a large portion of people in jail now are there on drug-related charges .\n",
      "Predicted answer:  And why is that ?\n",
      "Correct answer:  And why is that ?\n",
      "\n",
      "Context:  Absolute proof only exists in the abstract realms of logic and math .And liquor .\n",
      "Predicted answer:  Absolute proof only exists in the abstract realms of logic and math\n",
      "Correct answer:  Absolute proof only exists in the abstract realms of logic and math .\n",
      "\n",
      "Context:  As for the second part , no , you 've got it backward , rational belief is based on faith in a rational creator .I disagree , I need you to show me what part of reason is BASED on faith of a rational creator , based on evidence ( includes things that are self-evident ) . Unless you want me to accept your claim on faith ! ! -Mach\n",
      "Predicted answer:  rational belief is based on faith in a rational creator .\n",
      "Correct answer:  As for the second part , no , you 've got it backward , rational belief\n",
      "\n",
      "Context:  Not being able to change something would be an indication of not being omnipotent . Here is another example of your inadequacies .corrected above , thank you , minus the insult that followed . It still stands however as a rational rebuttal .\n",
      "Predicted answer:  Not being able to change something would be an indication of not being omnipotent .\n",
      "Correct answer:  Not being able to change something would be an indication of not being omnipotent .\n",
      "\n",
      "Context:  Look Bell - your point is made .We agree ! Excellent !\n",
      "Predicted answer:  Look Bell - your point is made .\n",
      "Correct answer:  your point is made\n",
      "\n",
      "Context:  Yes , that is the point !And you have yet to provide stats that prove that gun shows are a threat .\n",
      "Predicted answer:  Yes , that is the point !\n",
      "Correct answer:  that is the point !\n",
      "\n",
      "Context:  I have some questions for everyone here . For example , what is each side trying to prove ?Each side tries to support their own worldview . There are two positions , and sides are chosen . It 's human nature .\n",
      "Predicted answer:  I have some questions for everyone here . For example , what is each side trying to prove ?\n",
      "Correct answer:  what is each side trying to prove ?\n",
      "\n",
      "Context:  And to think : We actually got nut jobs like this in government postions .And way too many of them . Of course what do you expect witht the state run media , a solid lock on education to the point of propaganda and massive voter fraud . They do n't say the graveyards in Cook County IL vote early and often for nothing .\n",
      "Predicted answer:  We actually got nut jobs like this in government postions .\n",
      "Correct answer:  And to think : We actually got nut jobs like this in government postions .\n",
      "\n",
      "Context:  Though it does n't really say why , the Bible says that is what will happen . See Matthew 7 :13,14 . It 's part of God 's plan . Free will .What 's this ? Do we really get to pick apart the free will defense now ?\n",
      "Predicted answer:  the Bible says that is what will happen .\n",
      "Correct answer:  It 's part of God 's plan . Free will .\n",
      "\n",
      "Context:  We are all headed downhill . This contradicts the basic dogma of evolutionists . Life is not gaining complexity or creating new informationÂ….itÂ ’ s in a state of rapid decay and decline .See above .\n",
      "Predicted answer:  We are all headed downhill . This contradicts the basic dogma of evolutionists\n",
      "Correct answer:  We are all headed downhill .\n",
      "\n",
      "Context:  And I personally wo n't believe anything off of a site like that , nor would I believe anything that I got off a site that was blatantly anti-creationism .Well , where else is the information going to come from ? Nobody else cares about the creation vs. evolution debate except for creationists and evolutionists .\n",
      "Predicted answer:  And I personally wo n't believe anything off of a site like that\n",
      "Correct answer:  And I personally wo n't believe anything off of a site like that , nor would I believe anything that I got off a site\n",
      "\n",
      "Context:  Monkeys show sense of justice Absolutely amazing . And Capuchins , although bright relative to most other mammals , are n't as bright as chimps .Capuchins ? The monks ? http : //www.capuchin.com/ Are you saying monkeys are smarter than monks ?\n",
      "Predicted answer:  Monkeys show sense of justice Absolutely amazing .\n",
      "Correct answer:  Monkeys show sense of justice Absolutely amazing . And Capuchins , although bright relative to most other mammals\n",
      "\n",
      "Context:  And here 's something else I do n't get . Evolutionists ' concept of selection basically means `` survival of the fittest. ``From wikipedia : `` The phrase is a metaphor , not a scientific description ; and it is not generally used by biologists , who almost exclusively prefer to use the phrase 'natural selection'. ``\n",
      "Predicted answer:  Evolutionists ' concept of selection basically means `` survival of the fittest. ``\n",
      "Correct answer:  Evolutionists ' concept of selection basically means `` survival of the fittest. ``\n",
      "\n",
      "Context:  I 'm sure that Clive14 can clarify this for him/herself ,Really ? You 've sought to intervene so far . Why stop ?\n",
      "Predicted answer:  I 'm sure that Clive14 can clarify this for him/herself ,\n",
      "Correct answer:  I 'm sure that Clive14 can clarify this for him/herself ,\n",
      "\n",
      "Context:  Because it 's unfair that us little people can also own guns .I pretend I 'm rich and famous that way being surrounded by firepower do n't bother me as much and I feel better about it .\n",
      "Predicted answer:  Because it 's unfair that us little people can also own guns .\n",
      "Correct answer:  it 's unfair that us little people can also own guns .\n",
      "\n",
      "Context:  They assume that as evolution progressed - lots of elements of life are no longer useful .That happens , too . For example , our gene for vitamin C is broken and no longer works .\n",
      "Predicted answer:  They assume that as evolution progressed - lots of elements of life are no longer useful .\n",
      "Correct answer:  evolution progressed - lots of elements of life are no longer useful .\n",
      "\n",
      "Context:  there were state laws ( not the new admendments ) that made a same sex couple illegal . some of them being writen in the 1800 'sNO , these were all ammedments . all passed . All written recently . There are laws on the book from the 1800 's but that is n't what just passed .\n",
      "Predicted answer:  there were state laws ( not the new admendments ) that made a same sex couple illegal .\n",
      "Correct answer:  there were state laws ( not the new admendments ) that made a same sex couple illegal . some of them being writen in the 1800 's\n",
      "\n",
      "Context:  New York 's tough gun-control laws were central to its success in reducing crime .Really ?\n",
      "Predicted answer:  New York 's tough gun-control laws were central to its success in reducing crime .\n",
      "Correct answer:  New York 's tough gun-control laws were central to its success in reducing crime .\n",
      "\n",
      "Context:  Proof please .Actually , you should n't ask that . If they 're stolen , ( commonly from vehicles , as OC stated ) , well , would one have the leave them in a vehicle if he lives in a state that issues CCWs without having to go through a big legal hassle ? Not really\n",
      "Predicted answer:  Proof please .\n",
      "Correct answer:  Proof please .\n",
      "\n",
      "Context:  What part of school biology needs evolution to make sense ? taking out evolution is not like taking out algebra and equations of curves out of mathematics and still teaching calculus .So then I guess you could also debate that algebra serves no purpose as well .\n",
      "Predicted answer:  What part of school biology needs evolution to make sense ?\n",
      "Correct answer:  taking out evolution is not like taking out algebra\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(\"Context: \", small_eval_set[i][\"context\"])\n",
    "    print(\"Predicted answer: \", predicted_answers[i][\"prediction_text\"])\n",
    "    print(\"Correct answer: \", theoretical_answers[i][\"answers\"][\"text\"][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(X, Y):\n",
    "    # find the length of the strings\n",
    "    X_token = word_tokenize(X)\n",
    "    Y_token = word_tokenize(Y)\n",
    "\n",
    "    X = [x for x in X_token if x not in string.punctuation]\t\n",
    "    Y = [x for x in Y_token if x not in string.punctuation]\t\n",
    "\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "\n",
    "    total_length = m + n\n",
    " \n",
    "    # declaring the array for storing the dp values\n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    " \n",
    "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0 :\n",
    "                L[i][j] = 0\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1]+1\n",
    "            else:\n",
    "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    " \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
    "    LSC = L[m][n]\n",
    "    score = (LSC/(total_length - LSC))\n",
    "    return score\n",
    "# end of function lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  So it 's not evidence vs evidence , it 's evidence vs religious belief .Well , youÂ ’ re just begging the question of what is evidence . You are saying religious belief ( others might say religious knowledge ) is not evidence . If it is scientific , it is evidence . If it is not scientific , it is not evidence . Have I got it right ?\n",
      "Predicted answer:  So it 's not evidence vs evidence , it 's evidence vs religious belief .\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lcs_socre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(correct_answers)):\n\u001b[1;32m     13\u001b[0m \tlcs_score \u001b[39m=\u001b[39m lcs(predicted_answers[i][\u001b[39m\"\u001b[39m\u001b[39mprediction_text\u001b[39m\u001b[39m\"\u001b[39m], correct_answers[j])\n\u001b[0;32m---> 14\u001b[0m \tscore \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(score, lcs_socre)\n\u001b[1;32m     15\u001b[0m \tapplied_answer \u001b[39m=\u001b[39m correct_answers[j] \u001b[39mif\u001b[39;00m lcs_score \u001b[39m==\u001b[39m score \u001b[39melse\u001b[39;00m applied_answer\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mScore: \u001b[39m\u001b[39m\"\u001b[39m, score)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lcs_socre' is not defined"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "\n",
    "for i in range (50):\n",
    "\tprint(\"Context: \", small_eval_set[i][\"context\"])\n",
    "\tprint(\"Predicted answer: \", predicted_answers[i][\"prediction_text\"])\n",
    "\tu_id = df_train.loc[df_train[\"id\"] == predicted_answers[i][\"id\"]]['u_id'].values[0]\n",
    "\tcorrect_answers = df_all.loc[df_all[\"id\"] == u_id]['q\\''].values\n",
    "\t# print(\"Correct answers: \", correct_answers)\n",
    "\n",
    "\tscore = 0\n",
    "\tapplied_answer = \"\"\n",
    "\tfor j in range(len(correct_answers)):\n",
    "\t\tlcs_score = lcs(predicted_answers[i][\"prediction_text\"], correct_answers[j])\n",
    "\t\tscore = max(score, lcs_score)\n",
    "\t\tapplied_answer = correct_answers[j] if lcs_score == score else applied_answer\n",
    "\t\t\n",
    "\tprint(\"Score: \", score)\n",
    "\tprint(\"Applied answer: \", applied_answer)\n",
    "\n",
    "\tprint()\n",
    "\n",
    "\n",
    "\t# print(\"Correct answers: \",  )\n",
    "\n",
    "# df_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dm_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a1b15c7b09c59f07da701710145ac380141b18bf7573e712d1ad76edd45c540"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
